# Tests End-to-End (E2E) - Analysis Service

Este directorio contiene tests end-to-end comprensivos para el servicio de anÃ¡lisis de archivos de configuraciÃ³n de red.

## ğŸ“‹ DescripciÃ³n

Los tests E2E validan el flujo completo del servicio desde la peticiÃ³n HTTP hasta la respuesta, incluyendo:

- âœ… AutenticaciÃ³n y autorizaciÃ³n
- âœ… ValidaciÃ³n de parÃ¡metros  
- âœ… EncriptaciÃ³n/desencriptaciÃ³n de archivos
- âœ… IntegraciÃ³n con servicios externos (Config Service, Gemini API)
- âœ… Persistencia en MongoDB
- âœ… Manejo de errores y casos lÃ­mite
- âœ… Performance y logging

## ğŸ—‚ï¸ Estructura de Archivos

```
test/e2e/
â”œâ”€â”€ __init__.py                    # Marcador de paquete Python
â”œâ”€â”€ conftest.py                    # ConfiguraciÃ³n y fixtures compartidas
â”œâ”€â”€ test_health_endpoint.py        # Tests del endpoint de health
â”œâ”€â”€ test_analysis_endpoint.py      # Tests del endpoint principal de anÃ¡lisis
â”œâ”€â”€ test_authentication.py         # Tests de autenticaciÃ³n y autorizaciÃ³n
â”œâ”€â”€ test_error_scenarios.py        # Tests de manejo de errores
â”œâ”€â”€ test_integration_flow.py       # Tests de flujo completo de integraciÃ³n
â”œâ”€â”€ pytest.ini                     # ConfiguraciÃ³n de pytest
â””â”€â”€ README.md                      # Esta documentaciÃ³n
```

## ğŸš€ EjecuciÃ³n de Tests

### Prerrequisitos

1. **Python 3.8+** instalado
2. **Dependencias** instaladas:
   ```bash
   pip install -r requirements-test.txt
   ```

### MÃ©todos de EjecuciÃ³n

#### 1. Script Automatizado (Recomendado)

```bash
# Desde el directorio raÃ­z del analysis-service
python run_e2e_tests.py
```

**Opciones disponibles:**
```bash
# Ejecutar todos los tests
python run_e2e_tests.py

# Con reporte de cobertura
python run_e2e_tests.py --coverage

# Solo tests rÃ¡pidos
python run_e2e_tests.py --fast

# Solo tests de autenticaciÃ³n
python run_e2e_tests.py --auth

# Tests especÃ­ficos
python run_e2e_tests.py --specific "health"

# Salida detallada
python run_e2e_tests.py --verbose
```

#### 2. Pytest Directo

```bash
# Cambiar al directorio de tests e2e
cd test/e2e

# Ejecutar todos los tests
pytest -v

# Con cobertura
pytest --cov=../../app --cov-report=html

# Tests especÃ­ficos
pytest test_health_endpoint.py -v
pytest -k "test_auth" -v
```

## ğŸ“Š Tipos de Tests

### 1. Health Endpoint (`test_health_endpoint.py`)
- âœ… VerificaciÃ³n de estado del servicio
- âœ… Acceso sin autenticaciÃ³n
- âœ… Formato de respuesta
- âœ… Headers CORS

### 2. Analysis Endpoint (`test_analysis_endpoint.py`)
- âœ… Flujo completo de anÃ¡lisis exitoso
- âœ… IntegraciÃ³n con Gemini API
- âœ… Proceso de encriptaciÃ³n/desencriptaciÃ³n
- âœ… ValidaciÃ³n de parÃ¡metros
- âœ… Manejo de errores de servicios externos

### 3. Authentication (`test_authentication.py`)
- âœ… AutenticaciÃ³n con token vÃ¡lido/invÃ¡lido
- âœ… Tokens expirados y malformados
- âœ… Middleware de autenticaciÃ³n
- âœ… Endpoints pÃºblicos vs protegidos
- âœ… Diferentes contextos de usuario

### 4. Error Scenarios (`test_error_scenarios.py`)
- âœ… Nombres de archivo invÃ¡lidos
- âœ… Timeouts de servicios externos
- âœ… Fallos de MongoDB
- âœ… Rate limits de Gemini API
- âœ… Fallos mÃºltiples simultÃ¡neos

### 5. Integration Flow (`test_integration_flow.py`)
- âœ… Flujo completo con configuraciÃ³n insegura
- âœ… Flujo completo con configuraciÃ³n segura
- âœ… Performance y logging del sistema

## ğŸ”§ ConfiguraciÃ³n

### Variables de Entorno

Los tests configuran automÃ¡ticamente estas variables:

```bash
ENVIRONMENT=test
ENCRYPTION_KEY=test_encryption_key_for_e2e
CONFIG_SERVICE_URL=http://localhost:8000
GEMINI_API_KEY=test_gemini_api_key
MONGODB_URL=mongodb://localhost:27017/test_db
PORT=8002
```

### Fixtures Disponibles

- `client`: Cliente sÃ­ncrono de FastAPI
- `async_client`: Cliente asÃ­ncrono de FastAPI
- `valid_auth_token`: Token de autenticaciÃ³n vÃ¡lido
- `mock_auth_middleware`: Mock del middleware de autenticaciÃ³n
- `mock_config_service`: Mock del servicio de configuraciÃ³n
- `mock_gemini_api`: Mock de Google Gemini API
- `mock_mongodb`: Mock de MongoDB
- `mock_encrypt_service`: Mock del servicio de encriptaciÃ³n

## ğŸ“ˆ Reportes y Cobertura

### Reporte de Cobertura HTML
```bash
python run_e2e_tests.py --coverage
# Genera: htmlcov/index.html
```

### Reporte en Terminal
```bash
pytest --cov=../../app --cov-report=term-missing
```

### MÃ©tricas Objetivo
- **Cobertura mÃ­nima**: 80%
- **Tiempo de ejecuciÃ³n**: < 30 segundos
- **Tasa de Ã©xito**: 100%

## ğŸ§ª Casos de Prueba Cubiertos

### Escenarios Exitosos
- âœ… AnÃ¡lisis de archivo con problemas de seguridad crÃ­ticos
- âœ… AnÃ¡lisis de archivo con configuraciÃ³n segura
- âœ… AutenticaciÃ³n exitosa con diferentes usuarios
- âœ… RecuperaciÃ³n ante fallos de servicios externos

### Escenarios de Error
- âœ… AutenticaciÃ³n fallida (token invÃ¡lido/expirado)
- âœ… ParÃ¡metros de entrada invÃ¡lidos
- âœ… Servicios externos no disponibles
- âœ… Fallos de encriptaciÃ³n/desencriptaciÃ³n
- âœ… Errores de base de datos

### Casos LÃ­mite
- âœ… Nombres de archivo con caracteres especiales
- âœ… Archivos extremadamente largos
- âœ… Timeouts de red
- âœ… Respuestas malformadas de APIs externas

## ğŸ” Debugging

### Logs Detallados
```bash
pytest -v -s --log-cli-level=DEBUG
```

### Tests EspecÃ­ficos
```bash
# Un test especÃ­fico
pytest test_health_endpoint.py::TestHealthEndpoint::test_health_check_sync -v

# Tests que fallan
pytest --lf

# Tests mÃ¡s lentos
pytest --durations=10
```

### Modo Debugging
```bash
# Con breakpoints
pytest --pdb

# Con coverage y debugging
pytest --cov=../../app --pdb-trace
```

## ğŸ—ï¸ Arquitectura de Tests

### PatrÃ³n de DiseÃ±o
- **Arrange**: ConfiguraciÃ³n de mocks y datos
- **Act**: EjecuciÃ³n de la peticiÃ³n HTTP
- **Assert**: ValidaciÃ³n de respuesta y efectos

### Estrategia de Mocking
- **Servicios externos**: Completamente mockeados
- **Base de datos**: Mock en memoria
- **AutenticaciÃ³n**: Mock configurable
- **APIs externas**: Respuestas controladas

### Aislamiento
- Cada test es independiente
- Estado limpio entre tests
- Mocks especÃ­ficos por test

## ğŸ“ Contribuir

### Agregar Nuevos Tests

1. **Identificar el escenario** a probar
2. **Elegir el archivo apropiado** o crear uno nuevo
3. **Seguir el patrÃ³n AAA** (Arrange, Act, Assert)
4. **Usar fixtures existentes** cuando sea posible
5. **Documentar el propÃ³sito** del test

### Ejemplo de Test
```python
@pytest_asyncio.async_test
async def test_nuevo_escenario(
    self, 
    async_client, 
    valid_auth_token,
    mock_auth_middleware,
    # ... otros fixtures necesarios
):
    """Test: descripciÃ³n clara del escenario"""
    # Arrange
    headers = {"Authorization": valid_auth_token}
    params = {"filename": "test.txt"}
    
    # Act
    response = await async_client.get("/api/v1/analyze", headers=headers, params=params)
    
    # Assert
    assert response.status_code == status.HTTP_200_OK
    data = response.json()
    assert data["success"] is True
```

## ğŸš¨ Troubleshooting

### Problemas Comunes

1. **Tests lentos**: Verificar que los mocks estÃ©n configurados correctamente
2. **Fallos de importaciÃ³n**: Asegurar que `PYTHONPATH` incluya el directorio raÃ­z
3. **Errores de fixtures**: Verificar que `conftest.py` estÃ© en el directorio correcto
4. **Fallos de async**: Usar `@pytest_asyncio.async_test` para tests asÃ­ncronos

### VerificaciÃ³n RÃ¡pida
```bash
# Verificar que pytest encuentra los tests
pytest --collect-only

# Verificar fixtures disponibles
pytest --fixtures

# Test de conectividad bÃ¡sica
pytest test_health_endpoint.py::TestHealthEndpoint::test_health_check_sync -v
```

## ğŸ“ Soporte

Para problemas con los tests E2E:

1. **Verificar logs** de ejecuciÃ³n
2. **Revisar configuraciÃ³n** de entorno
3. **Validar dependencias** instaladas
4. **Consultar documentaciÃ³n** del proyecto principal

---

**Nota**: Estos tests estÃ¡n diseÃ±ados para ejecutarse en un entorno aislado con mocks. No requieren servicios externos reales funcionando. 